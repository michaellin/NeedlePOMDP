{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Needle Insertion Markov Decision Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "using POMDPs\n",
    "using Distributions\n",
    "using POMDPToolbox\n",
    "using PyPlot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## States\n",
    "The data container below represents the state of the agent in the grid world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type NeedleState \n",
    "    x::Int64 # x position\n",
    "    y::Int64 # y position\n",
    "    psi::Int64 # orientation\n",
    "    bumped::Bool # did we bump the wall?\n",
    "    done::Bool # are we in a terminal state?\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some convenience functions for working with the NeedleState. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initial state constructor\n",
    "NeedleState(x::Int64, y::Int64, psi::Int64) = NeedleState(x,y,psi,false,false)\n",
    "# checks if the position of two states are the same\n",
    "posequal(s1::NeedleState, s2::NeedleState) = s1.x == s2.x && s1.y == s2.y && s1.psi == s2.psi\n",
    "# copies state s2 to s1\n",
    "function Base.copy!(s1::NeedleState, s2::NeedleState) \n",
    "    s1.x = s2.x\n",
    "    s1.y = s2.y\n",
    "    s1.psi = s2.psi\n",
    "    s1.bumped = s2.bumped\n",
    "    s1.done = s2.done\n",
    "    s1\n",
    "end\n",
    "# if you want to use Monte Carlo Tree Search, you will need to define the functions below\n",
    "Base.hash(s::NeedleState, h::UInt64 = zero(UInt64)) = hash(s.x, hash(s.y, hash(s.psi, hash(s.bumped, hash(s.done, h)))))\n",
    "Base.isequal(s1::NeedleState,s2::NeedleState) = s1.x == s2.x && s1.y == s2.y && s1.psi == s2.psi && s1.bumped == s2.bumped && s1.done == s2.done;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actions\n",
    "Since our action is simply the direction the agent chooses to go (i.e. cw, ccw), we can use a Symbol to represent it. Symbols are special types in Julia that allow for nice represntation of complex data. However, in our case a string could serve the same purpose as the symbol or even and integer, so feel free to use what you're most comfortable with. Note that in this case, we will not define a type for our action, instead we represent it directly with a symbol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MDP\n",
    "The Needle data container is defined below. It holds all the information we need to define the MDP tuple $$(\\mathcal{S}, \\mathcal{A}, T, R).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the needle mdp type\n",
    "type Needle <: MDP{NeedleState, Symbol} # Note that our MDP is parametarized by the state and the action\n",
    "    size_x::Int64 # x size of the grid\n",
    "    size_y::Int64 # y size of the grid\n",
    "    size_psi::Int64 # number of orientation bins\n",
    "    reward_states::Vector{NeedleState} # target/obstacle states\n",
    "    reward_values::Vector{Float64} # reward values for those states\n",
    "#     bounds_penalty::Float64 # penalty for bumping the wall\n",
    "    tprob::Array{Float64} # probability of transitioning to the desired state\n",
    "    discount_factor::Float64 # disocunt factor\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on, I want to create a constructor for Needle for convenience. Currently, if I want to create an instance of Needle, I have to pass in all of fields inside the Needle container (size_x, size_y, etc). The function below will return a Needle type with all the fields filled with some default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196-element Array{NeedleState,1}:\n",
       " NeedleState(8,4,1,false,false) \n",
       " NeedleState(8,4,2,false,false) \n",
       " NeedleState(8,4,3,false,false) \n",
       " NeedleState(8,4,4,false,false) \n",
       " NeedleState(8,4,5,false,false) \n",
       " NeedleState(8,4,6,false,false) \n",
       " NeedleState(8,4,7,false,false) \n",
       " NeedleState(8,4,8,false,false) \n",
       " NeedleState(4,6,1,false,false) \n",
       " NeedleState(4,6,2,false,false) \n",
       " NeedleState(4,6,3,false,false) \n",
       " NeedleState(4,6,4,false,false) \n",
       " NeedleState(4,6,5,false,false) \n",
       " â‹®                              \n",
       " NeedleState(6,10,4,false,false)\n",
       " NeedleState(7,10,4,false,false)\n",
       " NeedleState(8,10,4,false,false)\n",
       " NeedleState(9,10,4,false,false)\n",
       " NeedleState(2,10,5,false,false)\n",
       " NeedleState(3,10,5,false,false)\n",
       " NeedleState(4,10,5,false,false)\n",
       " NeedleState(5,10,5,false,false)\n",
       " NeedleState(6,10,5,false,false)\n",
       " NeedleState(7,10,5,false,false)\n",
       " NeedleState(8,10,5,false,false)\n",
       " NeedleState(9,10,5,false,false)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we use key worded arguments so we can change any of the values we pass in \n",
    "function Needle(;sx::Int64 = 10, # size_x\n",
    "                sy::Int64 = 10, # size_y\n",
    "                spsi::Int64 = 8, # size_psi\n",
    "                rs::Vector{NeedleState} = [[NeedleState(8,4,psi) for psi = 1:spsi]; # target states\n",
    "                                            [NeedleState(4,6,psi) for psi = 1:spsi]; # obstacle states\n",
    "                                            [NeedleState(1,y,psi) for y = 1:sy, psi = 3:7][:]; # boundary states\n",
    "                                            [NeedleState(sx,y,psi) for y = 1:sy, psi = [1:3;7:spsi]][:];\n",
    "                                            [NeedleState(x,1,psi) for x = 2:sx-1, psi = [5:spsi;1]][:];\n",
    "                                            [NeedleState(x,sy,psi) for x = 2:sx-1, psi = 1:5][:]],\n",
    "                rv::Vector{Float64} = [fill(50.0,spsi); fill(-20.0,spsi); fill(-5,(2*sx+2*sy-4)*5)],\n",
    "                tp::Array{Float64} = [0.05, 0.9, 0.05, 0.0], # tprob\n",
    "                discount_factor::Float64 = 0.9)\n",
    "    return Needle(sx, sy, spsi, rs, rv, tp, discount_factor)\n",
    "end\n",
    "\n",
    "# we can now create a NeedleState mdp instance like this:\n",
    "mdp = Needle()\n",
    "mdp.reward_states # mdp contains all the defualt values from the constructor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State Space ($ \\mathcal{S}$)\n",
    "The state space in an MDP represents all the states in the problem. There are two primary functionalities that we want our spaces to support. We want to be able to iterate over the state space (for Value Iteration for example), and sometimes we want to be able to sample form the state space (used in some POMDP solvers). In this notebook, we will only look at iterable state spaces. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type StateSpace <: AbstractSpace\n",
    "    states::Vector{NeedleState}\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we can iterate over elements of an array, and our problem is small, we can store all of our states in an array. If your problem is very large (tens of millions of states), it might be worthwhile to create an iterator over your state space. See [this](http://stackoverflow.com/questions/25028539/how-to-implement-an-iterator-in-julia) post on stackoverflow on making simple iterators. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function POMDPs.states(mdp::Needle)\n",
    "    s = NeedleState[] # initialize an array of NeedleStates\n",
    "    # loop over all our states, remeber there are two binary variables: done (d) and bumped(b)\n",
    "    for d = 0:1, b = 0:1, y = 1:mdp.size_y, x = 1:mdp.size_x, psi = 1:mdp.size_psi\n",
    "        push!(s, NeedleState(x,y,psi,b,d))\n",
    "    end\n",
    "    return StateSpace(s)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To finish up we need to define a function that returns the iterator over the state space. Remeber ```states(...)``` returns the state space type, and our iterator is hidden inside of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function POMDPs.iterator(space::StateSpace)\n",
    "    return space.states \n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to be able to uniformly sample for our state space. A sampling function for doing this is fairly simple to implement if you already have an array of all your states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function POMDPs.rand(rng::AbstractRNG, space::StateSpace, s::NeedleState)\n",
    "    sp = space.states[rand(rng, 1:end)]\n",
    "    copy!(s, sp)\n",
    "    s\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action Space ($\\mathcal{A}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The action space is the set of all actions availiable to the agent. In the grid world problem the action space consists of up, down, left, and right. Let's define the type for our action space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type ActionSpace <: AbstractSpace\n",
    "    actions::Vector{Symbol}\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now write a function called actions that returns our action space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function POMDPs.actions(mdp::Needle)\n",
    "    acts = [:cw, :ccw]\n",
    "    return ActionSpace(acts)\n",
    "end;\n",
    "POMDPs.actions(mdp::Needle, s::NeedleState, as::ActionSpace=actions(mdp)) = as;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function POMDPs.iterator(space::ActionSpace)\n",
    "    return space.actions \n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function POMDPs.rand(rng::AbstractRNG, space::ActionSpace, a::Symbol)\n",
    "    return space.actions[rand(rng, 1:end)]\n",
    "end;\n",
    "function POMDPs.rand(rng::AbstractRNG, space::ActionSpace)\n",
    "    a = NeedleAction(:cw)\n",
    "    return rand(rng, space, a)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To finish up, we add a couple of initializer functions for out state and action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "POMDPs.create_state(mdp::Needle) = NeedleState(1,1,1)\n",
    "POMDPs.create_action(mdp::Needle) = :cw;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since MDPs are probabilistic models, we have to deal with probability distributions. In this section, we outline how to define probability distriubtions, and what tools are availiable to help you with the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transition Distribution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are familiar with MDPs, you know that the transition function $T(s' \\mid s, a)$ captures the dynamics of the system. Specifically, $T(s' \\mid s, a)$ is a real value that defines the probabiltiy of transitioning to state $s'$ given that you took action $a$ in state $s$. The transition distirubtion $T(\\cdot \\mid s, a)$ is a slightly different construct. This is the actual distribution over the states that our agent can reach given that its in state $s$ and took action $a$. In other words this is the distribution over $s'$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to implement transition distributions for your problem. Your choice of distribution as well as how you implement it will heavily depend on your problem. [Distributions.jl](https://github.com/JuliaStats/Distributions.jl) provides support for many common univariate and multivarite distributions. Below is how we implement the one for grid world. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type NeedleDistribution <: AbstractDistribution\n",
    "    neighbors::Array{NeedleState} # the states s' in the distribution\n",
    "    probs::Array{Float64} # the probability corresponding to each state s'\n",
    "    cat::Categorical # this comes from Distributions.jl and is used for sampling\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce memory allocation, the POMDPs.jl interface defines some initalization functions that return initial types to be filled lated. This function returns the distribution type filled with some values. We don't care what the distribution container has in it, because it will be modified at each call to the transition function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function POMDPs.create_transition_distribution(mdp::Needle)\n",
    "    # can have at most five neighbors in grid world\n",
    "    neighbors =  [NeedleState(i,i,1) for i = 1:5]\n",
    "    probabilities = zeros(5) + 1.0/5.0\n",
    "    cat = Categorical(5)\n",
    "    return NeedleDistribution(neighbors, probabilities, cat)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function we want is ```domain(...)```. For discrete state distributions, domain returns an iterator over the states in that distributions (this is just the neighbors array in our distriubtion type). The function takes on the following form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function POMDPs.iterator(d::NeedleDistribution)\n",
    "    return d.neighbors\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's implement the probability density function (really this is a probability mass function since the distriubtion is discrete, but we overload the pdf function name to serve as both). Below is a fairly inneficient impelemntation of pdf. For the discrete distribution in our problem, the pdf function returns the probability of drawing the state s from the distribution d. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function POMDPs.pdf(d::NeedleDistribution, s::NeedleState)\n",
    "    for (i, sp) in enumerate(d.neighbors)\n",
    "        if s == sp\n",
    "            return d.probs[i]\n",
    "        end\n",
    "    end   \n",
    "    return 0.0\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we want to implement a smapling function that can draw samples from our distribution. Once again, there are many ways to do this, but we recommend using Distributions.jl. We use POMDPDistributions which mimicks a lot of the behavior of Distributions.jl. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function POMDPs.rand(rng::AbstractRNG, d::NeedleDistribution, s::NeedleState)\n",
    "    d.cat = Categorical(d.probs) # init the categorical distribution\n",
    "    ns = d.neighbors[rand(d.cat)] # sample a neighbor state according to the distribution c\n",
    "    copy!(s, ns)\n",
    "    return s # return the pointer to s\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To recap, there are two functionalities that we require your distirbutions to support. We want to be able to sample from them using the ```rand!(...)``` function, and we want to obtain the probability density using the ```pdf(...)``` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transition Model (T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will define the system dynamics of the gird world MDP. In POMDPs.jl, we work with transition distirbution functions $T(s' \\mid s, a)$, so we want to write a function that can generate the transition distributions over $s'$ for us given an $(s, a)$ pair. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the transition function we want to fill the neighbors in our distribution d with the reachable states from the state, action pair. We want to fill the probs in our distirbution d with the probabilities of reaching that neighbor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# transition helpers\n",
    "function inbounds(mdp::Needle,x::Int64,y::Int64,psi::Int64)\n",
    "    if 1 <= x <= mdp.size_x && 1 <= y <= mdp.size_y && 1 <= psi <= mdp.size_psi\n",
    "        return true\n",
    "    else\n",
    "        return false\n",
    "    end\n",
    "end\n",
    "\n",
    "function inbounds(mdp::Needle,state::NeedleState)\n",
    "    x = state.x\n",
    "    y = state.y\n",
    "    psi = state.psi\n",
    "    return inbounds(mdp, x, y, psi)\n",
    "end\n",
    "\n",
    "###########################################################\n",
    "\n",
    "function atbounds(mdp::Needle,x::Int64,y::Int64,psi::Int64)\n",
    "    # at bounds if: at wall, facing outward or at corner\n",
    "    if (x == 1 || x == mdp.size_x) && (y == 1 || y == mdp.size_y) # at corner\n",
    "        return true\n",
    "        elseif (x == 1 && 3 <= psi <= 7) || (x == mdp.size_x && (7 <= psi || psi <= 3) ) ||\n",
    "        (y == 1 && (5 <= psi || psi <= 1) ) || (y == mdp.size_y && 1 <= psi <= 5) # at wall, facing outward\n",
    "        return true\n",
    "    else\n",
    "        return false\n",
    "    end\n",
    "end\n",
    "\n",
    "function atbounds(mdp::Needle,state::NeedleState)\n",
    "    x = state.x\n",
    "    y = state.y\n",
    "    psi = state.psi\n",
    "    return atbounds(mdp, x, y, psi)\n",
    "end\n",
    "\n",
    "###########################################################\n",
    "\n",
    "function fill_probability!(p::Vector{Float64}, val::Float64, index::Int64)\n",
    "    for i = 1:length(p)\n",
    "        if i == index\n",
    "            p[i] = val\n",
    "        else\n",
    "            p[i] = 0.0\n",
    "        end\n",
    "    end\n",
    "end;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function POMDPs.transition(mdp::Needle,\n",
    "                            state::NeedleState,\n",
    "                            action::Symbol,\n",
    "                            d::NeedleDistribution=create_transition_distribution(mdp))\n",
    "    tp = mdp.tprob\n",
    "    \n",
    "    a = action\n",
    "    x = state.x\n",
    "    y = state.y\n",
    "    psi = state.psi\n",
    "    \n",
    "    neighbors = d.neighbors\n",
    "    probability = d.probs\n",
    "    \n",
    "    # let's handle the done case first\n",
    "    if state.done\n",
    "        # can only transition to the same done state\n",
    "        fill!(probability, 0.0)\n",
    "        probability[1] = 1.0\n",
    "        copy!(neighbors[1], state)\n",
    "        # when we sample d, we will only get the state in neighbors[1] - our done state\n",
    "        return d\n",
    "    end\n",
    "    \n",
    "    fill!(probability, 0.0)\n",
    "\n",
    "    if a == :ccw\n",
    "        if psi == 1\n",
    "            neighbors[1].x = x+1; neighbors[1].y = y;   neighbors[1].psi = psi; \n",
    "            neighbors[2].x = x+1; neighbors[2].y = y;   neighbors[2].psi = psi+1;\n",
    "            neighbors[3].x = x+1; neighbors[3].y = y+1; neighbors[3].psi = psi+1;\n",
    "            neighbors[4].x = x+1; neighbors[4].y = y+1; neighbors[4].psi = psi+2;\n",
    "        elseif psi == 2\n",
    "            neighbors[1].x = x+1; neighbors[1].y = y+1; neighbors[1].psi = psi; \n",
    "            neighbors[2].x = x+1; neighbors[2].y = y+1; neighbors[2].psi = psi+1;\n",
    "            neighbors[3].x = x;   neighbors[3].y = y+1; neighbors[3].psi = psi+1;\n",
    "            neighbors[4].x = x;   neighbors[4].y = y+1; neighbors[4].psi = psi+2;\n",
    "        elseif psi == 3\n",
    "            neighbors[1].x = x;   neighbors[1].y = y+1; neighbors[1].psi = psi; \n",
    "            neighbors[2].x = x;   neighbors[2].y = y+1; neighbors[2].psi = psi+1;\n",
    "            neighbors[3].x = x-1; neighbors[3].y = y+1; neighbors[3].psi = psi+1;\n",
    "            neighbors[4].x = x-1; neighbors[4].y = y+1; neighbors[4].psi = psi+2;\n",
    "        elseif psi == 4\n",
    "            neighbors[1].x = x-1; neighbors[1].y = y+1; neighbors[1].psi = psi; \n",
    "            neighbors[2].x = x-1; neighbors[2].y = y+1; neighbors[2].psi = psi+1;\n",
    "            neighbors[3].x = x-1; neighbors[3].y = y;   neighbors[3].psi = psi+1;\n",
    "            neighbors[4].x = x-1; neighbors[4].y = y;   neighbors[4].psi = psi+2;\n",
    "        elseif psi == 5\n",
    "            neighbors[1].x = x-1; neighbors[1].y = y;   neighbors[1].psi = psi; \n",
    "            neighbors[2].x = x-1; neighbors[2].y = y;   neighbors[2].psi = psi+1;\n",
    "            neighbors[3].x = x-1; neighbors[3].y = y-1; neighbors[3].psi = psi+1;\n",
    "            neighbors[4].x = x-1; neighbors[4].y = y-1; neighbors[4].psi = psi+2;\n",
    "        elseif psi == 6\n",
    "            neighbors[1].x = x-1; neighbors[1].y = y-1; neighbors[1].psi = psi; \n",
    "            neighbors[2].x = x-1; neighbors[2].y = y-1; neighbors[2].psi = psi+1;\n",
    "            neighbors[3].x = x;   neighbors[3].y = y-1; neighbors[3].psi = psi+1;\n",
    "            neighbors[4].x = x;   neighbors[4].y = y-1; neighbors[4].psi = psi+2;\n",
    "        elseif psi == 7\n",
    "            neighbors[1].x = x;   neighbors[1].y = y-1; neighbors[1].psi = psi; \n",
    "            neighbors[2].x = x;   neighbors[2].y = y-1; neighbors[2].psi = psi+1;\n",
    "            neighbors[3].x = x+1; neighbors[3].y = y-1; neighbors[3].psi = psi+1;\n",
    "            neighbors[4].x = x+1; neighbors[4].y = y-1; neighbors[4].psi = psi+2;\n",
    "        elseif psi == 8\n",
    "            neighbors[1].x = x+1; neighbors[1].y = y-1; neighbors[1].psi = psi; \n",
    "            neighbors[2].x = x+1; neighbors[2].y = y-1; neighbors[2].psi = psi+1;\n",
    "            neighbors[3].x = x+1; neighbors[3].y = y;   neighbors[3].psi = psi+1;\n",
    "            neighbors[4].x = x+1; neighbors[4].y = y;   neighbors[4].psi = psi+2;\n",
    "        end\n",
    "    elseif a == :cw\n",
    "        if psi == 1\n",
    "            neighbors[1].x = x+1; neighbors[1].y = y;   neighbors[1].psi = psi; \n",
    "            neighbors[2].x = x+1; neighbors[2].y = y;   neighbors[2].psi = psi+7;\n",
    "            neighbors[3].x = x+1; neighbors[3].y = y-1; neighbors[3].psi = psi+7;\n",
    "            neighbors[4].x = x+1; neighbors[4].y = y-1; neighbors[4].psi = psi+6;\n",
    "        elseif psi == 2\n",
    "            neighbors[1].x = x+1; neighbors[1].y = y+1; neighbors[1].psi = psi; \n",
    "            neighbors[2].x = x+1; neighbors[2].y = y+1; neighbors[2].psi = psi+7;\n",
    "            neighbors[3].x = x+1; neighbors[3].y = y;   neighbors[3].psi = psi+7;\n",
    "            neighbors[4].x = x+1; neighbors[4].y = y;   neighbors[4].psi = psi+6;\n",
    "        elseif psi == 3\n",
    "            neighbors[1].x = x;   neighbors[1].y = y+1; neighbors[1].psi = psi; \n",
    "            neighbors[2].x = x;   neighbors[2].y = y+1; neighbors[2].psi = psi+7;\n",
    "            neighbors[3].x = x+1; neighbors[3].y = y+1; neighbors[3].psi = psi+7;\n",
    "            neighbors[4].x = x+1; neighbors[4].y = y+1; neighbors[4].psi = psi+6;\n",
    "        elseif psi == 4\n",
    "            neighbors[1].x = x-1; neighbors[1].y = y+1; neighbors[1].psi = psi; \n",
    "            neighbors[2].x = x-1; neighbors[2].y = y+1; neighbors[2].psi = psi+7;\n",
    "            neighbors[3].x = x;   neighbors[3].y = y+1; neighbors[3].psi = psi+7;\n",
    "            neighbors[4].x = x;   neighbors[4].y = y+1; neighbors[4].psi = psi+6;\n",
    "        elseif psi == 5\n",
    "            neighbors[1].x = x-1; neighbors[1].y = y;   neighbors[1].psi = psi; \n",
    "            neighbors[2].x = x-1; neighbors[2].y = y;   neighbors[2].psi = psi+7;\n",
    "            neighbors[3].x = x-1; neighbors[3].y = y+1; neighbors[3].psi = psi+7;\n",
    "            neighbors[4].x = x-1; neighbors[4].y = y+1; neighbors[4].psi = psi+6;\n",
    "        elseif psi == 6\n",
    "            neighbors[1].x = x-1; neighbors[1].y = y-1; neighbors[1].psi = psi; \n",
    "            neighbors[2].x = x-1; neighbors[2].y = y-1; neighbors[2].psi = psi+7;\n",
    "            neighbors[3].x = x-1; neighbors[3].y = y;   neighbors[3].psi = psi+7;\n",
    "            neighbors[4].x = x-1; neighbors[4].y = y;   neighbors[4].psi = psi+6;\n",
    "        elseif psi == 7\n",
    "            neighbors[1].x = x;   neighbors[1].y = y-1; neighbors[1].psi = psi; \n",
    "            neighbors[2].x = x;   neighbors[2].y = y-1; neighbors[2].psi = psi+7;\n",
    "            neighbors[3].x = x-1; neighbors[3].y = y-1; neighbors[3].psi = psi+7;\n",
    "            neighbors[4].x = x-1; neighbors[4].y = y-1; neighbors[4].psi = psi+6;\n",
    "        elseif psi == 8\n",
    "            neighbors[1].x = x+1; neighbors[1].y = y-1; neighbors[1].psi = psi; \n",
    "            neighbors[2].x = x+1; neighbors[2].y = y-1; neighbors[2].psi = psi+7;\n",
    "            neighbors[3].x = x;   neighbors[3].y = y-1; neighbors[3].psi = psi+7;\n",
    "            neighbors[4].x = x;   neighbors[4].y = y-1; neighbors[4].psi = psi+6;\n",
    "        end\n",
    "    end\n",
    "    # make sure psi is between 1 and 8\n",
    "    for i = 1:4\n",
    "        neighbors[i].psi = mod(neighbors[i].psi,8)\n",
    "        if neighbors[i].psi == 0\n",
    "            neighbors[i].psi = 8;\n",
    "        end\n",
    "    end\n",
    "    neighbors[5].x = x; neighbors[5].y = y; neighbors[5].psi = psi;\n",
    "    \n",
    "    # initialize bumped and done states \n",
    "    for i = 1:5 neighbors[i].bumped = false end\n",
    "    for i = 1:5 neighbors[i].done = false end\n",
    "    reward_states = mdp.reward_states\n",
    "    \n",
    "    # detection of done states\n",
    "    n = length(reward_states)\n",
    "    for i = 1:n\n",
    "        # terminate at target/obstacle\n",
    "        if posequal(state, reward_states[i])\n",
    "            fill_probability!(probability, 1.0, 5)\n",
    "            neighbors[5].done = true\n",
    "            return d\n",
    "        end\n",
    "        # terminate at boundary\n",
    "        if atbounds(mdp, state)\n",
    "            fill_probability!(probability, 1.0, 5)\n",
    "            neighbors[5].done = true\n",
    "            neighbors[5].bumped = true\n",
    "            return d\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    if !inbounds(mdp, neighbors[1]) || !inbounds(mdp, neighbors[2]) ||\n",
    "        !inbounds(mdp, neighbors[3]) || !inbounds(mdp, neighbors[4]) # at least one of the neighbors is outside bounds\n",
    "        fill_probability!(probability, 1.0, 5) # stuck in current state when terminated\n",
    "        neighbors[5].bumped = true     \n",
    "    else # none of the neighbors is outside bounds\n",
    "        probability[1:4] = tp\n",
    "    end\n",
    "    \n",
    "    return d\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward Model (R)\n",
    "The reward model $R(s,a,s')$ is a function that returns the reward of being in state $s$, taking an action $a$ from that state, and ending up in state $s'$. In our problem, we are rewarded for reaching a terimanl reward state (this could be positive or negative), and we are penalized for bumping into a wall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function POMDPs.reward(mdp::Needle, state::NeedleState, action::Symbol, statep::NeedleState) #deleted action\n",
    "    if state.done\n",
    "        return 0.0\n",
    "    end\n",
    "    r = 0.0\n",
    "    reward_states = mdp.reward_states\n",
    "    reward_values = mdp.reward_values\n",
    "    n = length(reward_states)\n",
    "    for i = 1:n\n",
    "        if posequal(state, reward_states[i]) # reward, obstacle and wall states\n",
    "            r += reward_values[i]\n",
    "        end\n",
    "    end\n",
    "    r += -1; # penalty for every step taken\n",
    "#     if state.bumped\n",
    "#         r += mdp.bounds_penalty\n",
    "#     end\n",
    "    \n",
    "    return r\n",
    "end;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous Functions\n",
    "We are almost done! Just a few simple functions left. First let's implement two functions that return the sizes of our state and action spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "POMDPs.n_states(mdp::Needle) = 4*mdp.size_x*mdp.size_y*mdp.size_psi\n",
    "POMDPs.n_actions(mdp::Needle) = 4\n",
    "POMDPs.discount(mdp::Needle) = mdp.discount_factor;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing we need is an indexing function. This allows us to index between the discrete utility array and the states in our problem. We will use the ```sub2ind()``` function from Julia base to help us here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function POMDPs.state_index(mdp::Needle, state::NeedleState)\n",
    "    sb = Int(state.bumped + 1)\n",
    "    sd = Int(state.done + 1)\n",
    "    return sub2ind((mdp.size_x, mdp.size_y, mdp.size_psi, 2, 2), state.x, state.y, state.psi, sb, sd)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's define a function that checks if a state is terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function POMDPs.isterminal(mdp::Needle, s::NeedleState)\n",
    "    s.done ? (return true) : (return false)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value Iteration Solver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each POMDPs.jl solver provides two data types for you to interface with. The first is the Solver type which contains solver parameters. The second is the Policy type. Let's see hwo we can use them to get an optimal action at a given state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 1, residual: 49.0, iteration run-time: 0.301120396, total run-time: 0.301120396\n",
      "Iteration : 2, residual: 34.7445, iteration run-time: 0.283177369, total run-time: 0.5842977650000001\n",
      "Iteration : 3, residual: 28.102453875000002, iteration run-time: 0.295485469, total run-time: 0.879783234\n",
      "Iteration : 4, residual: 18.81040309847817, iteration run-time: 0.300869599, total run-time: 1.180652833\n",
      "Iteration : 5, residual: 15.443737816421423, iteration run-time: 0.294412254, total run-time: 1.475065087\n",
      "Iteration : 6, residual: 12.146584586814578, iteration run-time: 0.296719424, total run-time: 1.771784511\n",
      "Iteration : 7, residual: 8.95037288182672, iteration run-time: 0.294057963, total run-time: 2.065842474\n",
      "Iteration : 8, residual: 6.082037257266345, iteration run-time: 0.296310506, total run-time: 2.3621529800000003\n",
      "Iteration : 9, residual: 2.531187330094252, iteration run-time: 0.297932381, total run-time: 2.660085361\n",
      "Iteration : 10, residual: 0.9565181585480205, iteration run-time: 0.294318834, total run-time: 2.954404195\n",
      "Iteration : 11, residual: 0.31644430541761426, iteration run-time: 0.295912267, total run-time: 3.250316462\n",
      "Iteration : 12, residual: 0.15775309572075624, iteration run-time: 0.292692678, total run-time: 3.5430091399999997\n",
      "Iteration : 13, residual: 0.11265921217649577, iteration run-time: 0.295788672, total run-time: 3.8387978119999997\n",
      "Iteration : 14, residual: 0.072151060587475, iteration run-time: 0.294269015, total run-time: 4.1330668269999995\n",
      "Iteration : 15, residual: 0.049356986417897986, iteration run-time: 0.295999464, total run-time: 4.429066291\n",
      "Iteration : 16, residual: 0.02854720716686021, iteration run-time: 0.294261019, total run-time: 4.72332731\n",
      "Iteration : 17, residual: 0.017333238695445452, iteration run-time: 0.299832953, total run-time: 5.023160263\n",
      "Iteration : 18, residual: 0.007665073720782178, iteration run-time: 0.292757295, total run-time: 5.315917558000001\n",
      "Iteration : 19, residual: 0.0048836074416129804, iteration run-time: 0.297641233, total run-time: 5.613558791000001\n",
      "Iteration : 20, residual: 0.004036416280813526, iteration run-time: 0.291443973, total run-time: 5.905002764000001\n",
      "Iteration : 21, residual: 0.0033173877056995593, iteration run-time: 0.292283743, total run-time: 6.197286507\n",
      "Iteration : 22, residual: 0.002719233867921389, iteration run-time: 0.294397152, total run-time: 6.491683659\n",
      "Iteration : 23, residual: 0.0022213956569512305, iteration run-time: 0.288510034, total run-time: 6.780193693\n",
      "Iteration : 24, residual: 0.0018109565191259946, iteration run-time: 0.289442333, total run-time: 7.069636026\n",
      "Iteration : 25, residual: 0.0014738181093498781, iteration run-time: 0.295695319, total run-time: 7.365331345\n",
      "Iteration : 26, residual: 0.0011980854262469975, iteration run-time: 0.292398924, total run-time: 7.657730269\n",
      "Iteration : 27, residual: 0.0009730598892110365, iteration run-time: 0.297247584, total run-time: 7.954977853\n"
     ]
    }
   ],
   "source": [
    "using DiscreteValueIteration\n",
    "\n",
    "# initialize the problem\n",
    "mdp = Needle()\n",
    "\n",
    "# initialize the solver\n",
    "# max_iterations: maximum number of iterations value iteration runs for (default is 100)\n",
    "# belres: the value of Bellman residual used in the solver (defualt is 1e-3)\n",
    "solver = ValueIterationSolver(max_iterations=100, belres=1e-3)\n",
    "\n",
    "# initialize the policy by passing in your problem\n",
    "policy_vi = ValueIterationPolicy(mdp)\n",
    "\n",
    "# solve for an optimal policy\n",
    "# if verbose=false, the text output will be supressed (false by default)\n",
    "solve(solver, mdp, policy_vi, verbose=true);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte-Carlo Tree Search Solver\n",
    "Monte-Carlo Tree Search (MCTS) is another MDP solver. It is an online method that looks for the best action from only the current state by building a search tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: using MCTS.mdp in module Main conflicts with an existing identifier.\n"
     ]
    }
   ],
   "source": [
    "using MCTS\n",
    "\n",
    "# initialize the problem\n",
    "mdp = Needle()\n",
    "\n",
    "# initialize the solver\n",
    "# the hyper parameters in MCTS can be tricky to set properly\n",
    "# n_iterations: the number of iterations that each search runs for\n",
    "# depth: the depth of the tree (how far away from the current state the algorithm explores)\n",
    "# exploration constant: this is how much weight to put into exploratory actions. \n",
    "# A good rule of thumb is to set the exploration constant to what you expect the upper bound on your average expected reward to be.\n",
    "solver = MCTSSolver(n_iterations=100, depth=10, exploration_constant=1.0)\n",
    "\n",
    "# initialize the policy by passing in your problem and the solver\n",
    "policy_MCTS = MCTSPolicy(solver, mdp);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total discounted reward: 15.397565390000006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10-element Array{NeedleState,1}:\n",
       " NeedleState(4,10,7,false,false)\n",
       " NeedleState(4,9,8,false,false) \n",
       " NeedleState(5,8,1,false,false) \n",
       " NeedleState(6,8,8,false,false) \n",
       " NeedleState(7,7,1,false,false) \n",
       " NeedleState(8,7,8,false,false) \n",
       " NeedleState(9,6,7,false,false) \n",
       " NeedleState(9,5,6,false,false) \n",
       " NeedleState(8,4,5,false,false) \n",
       " NeedleState(8,4,5,false,true)  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = NeedleState(4,10,7)\n",
    "hist_vi = HistoryRecorder()\n",
    "\n",
    "r = simulate(hist_vi, mdp, policy_vi, s)\n",
    "\n",
    "println(\"Total discounted reward: $r\")\n",
    "\n",
    "hist_vi.state_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# N = 100000\n",
    "# r_all = ones(1,N)\n",
    "# for i = 1:N\n",
    "#     r_all[i] = simulate(hist, mdp, policy_vi, s)\n",
    "# end\n",
    "# println(value(policy_vi, s))\n",
    "# mean(r_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total discounted reward: 18.219517100000004\n",
      "Target reached\n"
     ]
    }
   ],
   "source": [
    "s = NeedleState(4,10,7)\n",
    "\n",
    "hist_MCTS = HistoryRecorder()\n",
    "r = simulate(hist_MCTS, mdp, policy_MCTS, s)\n",
    "\n",
    "println(\"Total discounted reward: $r\")\n",
    "\n",
    "if hist_MCTS.state_hist[end].x == mdp.reward_states[1].x && hist_MCTS.state_hist[end].y == mdp.reward_states[1].y\n",
    "    println(\"Target reached\")\n",
    "else\n",
    "    println(\"Target missed\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "PyPlot.Figure(PyObject <matplotlib.figure.Figure object at 0x7f14ac372510>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for s in hist_MCTS.state_hist\n",
    "    plot(s.x,s.y,color=\"b\",marker=\"o\")\n",
    "    quiver(s.x,s.y,0.5*cos(s.psi*pi/4),0.5*sin(s.psi*pi/4))\n",
    "    hold(true)\n",
    "end\n",
    "plot([1 10 10 1 1]',[1 1 10 10 1]') # tissue bounds\n",
    "\n",
    "title(\"Needle tip trajectory\")\n",
    "axis(\"equal\")\n",
    "axis([0, 11, 0, 11])\n",
    "xlabel(\"x\")\n",
    "ylabel(\"y\")\n",
    "grid(true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
