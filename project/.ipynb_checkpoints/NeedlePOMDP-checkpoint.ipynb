{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Needle Insertion Markov Decision Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "using POMDPs\n",
    "using Distributions\n",
    "using POMDPToolbox\n",
    "using PyPlot\n",
    "importall Base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## States\n",
    "The data container below represents the state of the agent in the grid world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type NeedleState \n",
    "    x::Int64 # x position\n",
    "    y::Int64 # y position\n",
    "    psi::Int64 # orientation\n",
    "    bumped::Bool # did we bump the wall?\n",
    "    done::Bool # are we in a terminal state?\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some convenience functions for working with the NeedleState. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "== (generic function with 157 methods)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial state constructor\n",
    "NeedleState(x::Int64, y::Int64, psi::Int64) = NeedleState(x,y,psi,false,false)\n",
    "# checks if the position of two states are the same\n",
    "posequal(s1::NeedleState, s2::NeedleState) = s1.x == s2.x && s1.y == s2.y && s1.psi == s2.psi\n",
    "# copies state s2 to s1\n",
    "function Base.copy!(s1::NeedleState, s2::NeedleState) \n",
    "    s1.x = s2.x\n",
    "    s1.y = s2.y\n",
    "    s1.psi = s2.psi\n",
    "    s1.bumped = s2.bumped\n",
    "    s1.done = s2.done\n",
    "    s1\n",
    "end\n",
    "# if you want to use Monte Carlo Tree Search, you will need to define the functions below\n",
    "Base.hash(s::NeedleState, h::UInt64 = zero(UInt64)) = hash(s.x, hash(s.y, hash(s.psi, hash(s.bumped, hash(s.done, h)))))\n",
    "Base.isequal(s1::NeedleState,s2::NeedleState) = s1.x == s2.x && s1.y == s2.y && s1.psi == s2.psi && s1.bumped == s2.bumped && s1.done == s2.done;\n",
    "==(s1::NeedleState, s2::NeedleState) = (s1.x == s2.x && s1.y == s2.y && s1.psi == s2.psi && s1.bumped == s2.bumped && s1.done == s2.done)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POMDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the needle mdp type\n",
    "type Needle <: POMDP{NeedleState, Symbol, NeedleState} # Note that our MDP is parametarized by the state and the action\n",
    "    size_x::Int64 # x size of the grid\n",
    "    size_y::Int64 # y size of the grid\n",
    "    size_psi::Int64 # number of orientation bins\n",
    "    reward_states::Vector{NeedleState} # target/obstacle states\n",
    "    reward_values::Vector{Float64} # reward values for those states\n",
    "    tprob::Array{Float64} # probability of transitioning to the desired state\n",
    "    discount_factor::Float64 # disocunt factor\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Needle(10,10,8,NeedleState[NeedleState(8,4,1,false,false),NeedleState(8,4,2,false,false),NeedleState(8,4,3,false,false),NeedleState(8,4,4,false,false),NeedleState(8,4,5,false,false),NeedleState(8,4,6,false,false),NeedleState(8,4,7,false,false),NeedleState(8,4,8,false,false),NeedleState(4,6,1,false,false),NeedleState(4,6,2,false,false)  …  NeedleState(8,10,4,false,false),NeedleState(9,10,4,false,false),NeedleState(2,10,5,false,false),NeedleState(3,10,5,false,false),NeedleState(4,10,5,false,false),NeedleState(5,10,5,false,false),NeedleState(6,10,5,false,false),NeedleState(7,10,5,false,false),NeedleState(8,10,5,false,false),NeedleState(9,10,5,false,false)],[100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,-20.0,-20.0  …  -5.0,-5.0,-5.0,-5.0,-5.0,-5.0,-5.0,-5.0,-5.0,-5.0],[0.05,0.9,0.05,0.0],0.9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we use key worded arguments so we can change any of the values we pass in \n",
    "function Needle(;sx::Int64 = 10, # size_x\n",
    "                sy::Int64 = 10, # size_y\n",
    "                spsi::Int64 = 8, # size_psi\n",
    "                rs::Vector{NeedleState} = [[NeedleState(8,4,psi) for psi = 1:spsi]; # target states\n",
    "                                            [NeedleState(4,6,psi) for psi = 1:spsi]; # obstacle states\n",
    "                                            [NeedleState(1,y,psi) for y = 1:sy, psi = 3:7][:]; # boundary states\n",
    "                                            [NeedleState(sx,y,psi) for y = 1:sy, psi = [1:3;7:spsi]][:];\n",
    "                                            [NeedleState(x,1,psi) for x = 2:sx-1, psi = [5:spsi;1]][:];\n",
    "                                            [NeedleState(x,sy,psi) for x = 2:sx-1, psi = 1:5][:]],\n",
    "                rv::Vector{Float64} = [fill(100.0,spsi); fill(-20.0,spsi); fill(-5,(2*sx+2*sy-4)*5)],\n",
    "                tp::Array{Float64} = [0.05, 0.9, 0.05, 0.0], # tprob\n",
    "                discount_factor::Float64 = 0.9)\n",
    "    return Needle(sx, sy, spsi, rs, rv, tp, discount_factor)\n",
    "end\n",
    "\n",
    "# we can now create a NeedleState mdp instance like this:\n",
    "pomdp = Needle()\n",
    "#pomdp.reward_states # mdp contains all the defualt values from the constructor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State Space ($ \\mathcal{S}$) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type StateSpace <: AbstractSpace\n",
    "    states::Vector{NeedleState}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function POMDPs.states(pomdp::Needle)\n",
    "    s = NeedleState[] # initialize an array of NeedleStates\n",
    "    # loop over all our states, remeber there are two binary variables: done (d) and bumped(b)\n",
    "    for d = 0:1, b = 0:1, y = 1:pomdp.size_y, x = 1:pomdp.size_x, psi = 1:pomdp.size_psi\n",
    "        push!(s, NeedleState(x,y,psi,b,d))\n",
    "    end\n",
    "    return StateSpace(s)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function POMDPs.iterator(space::StateSpace)\n",
    "    return space.states \n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function POMDPs.rand(rng::AbstractRNG, space::StateSpace, s::NeedleState)\n",
    "    sp = space.states[rand(rng, 1:end)]\n",
    "    copy!(s, sp)\n",
    "    return s\n",
    "end;\n",
    "POMDPs.rand(rng::AbstractRNG, space::StateSpace) = space.states[rand(rng, 1:end)];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type NeedleDistribution <: AbstractDistribution\n",
    "    neighbors::Array{NeedleState} # the states s' in the distribution\n",
    "    probs::Array{Float64} # the probability corresponding to each state s'\n",
    "    cat::Categorical # this comes from Distributions.jl and is used for sampling\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function POMDPs.create_transition_distribution(pomdp::Needle)\n",
    "    # can have at most five neighbors in grid world\n",
    "    neighbors =  [NeedleState(i,i,1) for i = 1:5]\n",
    "    probabilities = zeros(5) + 1.0/5.0\n",
    "    cat = Categorical(5)\n",
    "    return NeedleDistribution(neighbors, probabilities, cat)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function POMDPs.iterator(d::NeedleDistribution)\n",
    "    return d.neighbors\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function POMDPs.pdf(d::NeedleDistribution, s::NeedleState)\n",
    "    for (i, sp) in enumerate(d.neighbors)\n",
    "        if s == sp\n",
    "            return d.probs[i]\n",
    "        end\n",
    "    end   \n",
    "    return 0.0\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function POMDPs.rand(rng::AbstractRNG, d::NeedleDistribution, s::NeedleState)\n",
    "    d.cat = Categorical(d.probs) # init the categorical distribution\n",
    "    ns = d.neighbors[rand(d.cat)] # sample a neighbor state according to the distribution c\n",
    "    copy!(s, ns)\n",
    "    return s # return the pointer to s\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action Space ($\\mathcal{A}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type ActionSpace <: AbstractSpace\n",
    "    actions::Vector{Symbol}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function POMDPs.actions(pomdp::Needle)\n",
    "    acts = [:cw, :ccw]\n",
    "    return ActionSpace(acts)\n",
    "end;\n",
    "POMDPs.actions(pomdp::Needle, s::NeedleState, as::ActionSpace=actions(pomdp)) = as;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function POMDPs.iterator(space::ActionSpace)\n",
    "    return space.actions \n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function POMDPs.rand(rng::AbstractRNG, space::ActionSpace, a::Symbol)\n",
    "    return space.actions[rand(rng, 1:end)]\n",
    "end;\n",
    "function POMDPs.rand(rng::AbstractRNG, space::ActionSpace)\n",
    "    a = NeedleAction(:cw)\n",
    "    return rand(rng, space, a)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial State Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type InitialStateDistribution <: AbstractDistribution\n",
    "    states::Array{NeedleState} # the states s' in the distribution\n",
    "    probs::Array{Float64} # the probability corresponding to each state s'\n",
    "end\n",
    "POMDPs.iterator(d::InitialStateDistribution) = d.states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function POMDPs.initial_state_distribution(pomdp::Needle)\n",
    "    s = iterator(states(pomdp));\n",
    "    ns = n_states(pomdp);\n",
    "    p = zeros(ns)+1.0/ns;\n",
    "    return InitialStateDistribution(s,p);\n",
    "end\n",
    "\n",
    "function POMDPs.initial_state_distribution(pomdp::Needle, state::NeedleState)\n",
    "    s = [state];\n",
    "    p = [1];\n",
    "    return InitialStateDistribution(s,p);\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function POMDPs.rand(rng::AbstractRNG, d::InitialStateDistribution, s::NeedleState)\n",
    "    cat = Categorical(d.probs) # init the categorical distribution\n",
    "    ns = d.states[rand(cat)] # sample a neighbor state according to the distribution c\n",
    "    copy!(s, ns)\n",
    "    return s # return the pointer to s\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function POMDPs.pdf(d::InitialStateDistribution, s::NeedleState)\n",
    "    for (i, sp) in enumerate(d.states)\n",
    "        if s == sp\n",
    "            return d.probs[i]\n",
    "        end\n",
    "    end   \n",
    "    return 0.0\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation Space ($\\mathcal{O}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type ObservationSpace <: AbstractSpace\n",
    "    obs::Vector{NeedleState}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function POMDPs.observations(pomdp::Needle)\n",
    "    s = NeedleState[] # initialize an array of GridWorldStates\n",
    "    # loop over all our states, remeber there are two binary variables:\n",
    "    # done (d) and bumped(b)\n",
    "    for d=0:1, b=0:1, psi = 1: pomdp.size_psi, y = 1:pomdp.size_y, x = 1:pomdp.size_x\n",
    "        push!(s, NeedleState(x,y,psi,b,d))\n",
    "    end\n",
    "    return ObservationSpace(s)\n",
    "end;\n",
    "\n",
    "POMDPs.observations(pomdp::Needle, s::NeedleState, obs::ObservationSpace=observations(pomdp)) = obs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function POMDPs.iterator(space::ObservationSpace)\n",
    "    return space.obs \n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type ObsDistribution <: AbstractDistribution\n",
    "    curr_obs::NeedleState # the current observation\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function POMDPs.create_observation_distribution(pomdp::Needle)\n",
    "    # can 9 states of uncertainty\n",
    "    # initialize to whatever\n",
    "    #neighbors, probabilities = generate_neighbors(pomdp, GridWorldState(1,1))\n",
    "    #neighbors =  [GridWorldState(i,i) for i = 1:9]\n",
    "    #probabilities = zeros(9) + 1.0/9.0\n",
    "    #cat = Categorical(1)\n",
    "    return ObsDistribution(NeedleState(1,1,1))\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function POMDPs.iterator(d::ObsDistribution)\n",
    "    return [d.curr_obs]\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function POMDPs.rand(rng::AbstractRNG, d::ObsDistribution, o::NeedleState)\n",
    "    return d.curr_obs # return the pointer to s\n",
    "end;\n",
    "POMDPs.rand(rng::AbstractRNG, d::ObsDistribution) = d.curr_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function POMDPs.pdf(d::ObsDistribution, o::NeedleState)\n",
    "    if o == d.curr_obs\n",
    "        return 1.0;\n",
    "    end\n",
    "    return 0.0;\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transition Model (T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# transition helpers\n",
    "function inbounds(pomdp::Needle,x::Int64,y::Int64,psi::Int64)\n",
    "    if 1 <= x <= pomdp.size_x && 1 <= y <= pomdp.size_y && 1 <= psi <= pomdp.size_psi\n",
    "        return true\n",
    "    else\n",
    "        return false\n",
    "    end\n",
    "end\n",
    "\n",
    "function inbounds(pomdp::Needle,state::NeedleState)\n",
    "    x = state.x\n",
    "    y = state.y\n",
    "    psi = state.psi\n",
    "    return inbounds(pomdp, x, y, psi)\n",
    "end\n",
    "\n",
    "###########################################################\n",
    "\n",
    "function atbounds(pomdp::Needle,x::Int64,y::Int64,psi::Int64)\n",
    "    # at bounds if: at wall, facing outward or at corner\n",
    "    if (x == 1 || x == pomdp.size_x) && (y == 1 || y == pomdp.size_y) # at corner\n",
    "        return true\n",
    "        elseif (x == 1 && 3 <= psi <= 7) || (x == pomdp.size_x && (7 <= psi || psi <= 3) ) ||\n",
    "        (y == 1 && (5 <= psi || psi <= 1) ) || (y == pomdp.size_y && 1 <= psi <= 5) # at wall, facing outward\n",
    "        return true\n",
    "    else\n",
    "        return false\n",
    "    end\n",
    "end\n",
    "\n",
    "function atbounds(pomdp::Needle,state::NeedleState)\n",
    "    x = state.x\n",
    "    y = state.y\n",
    "    psi = state.psi\n",
    "    return atbounds(pomdp, x, y, psi)\n",
    "end\n",
    "\n",
    "###########################################################\n",
    "\n",
    "function fill_probability!(p::Vector{Float64}, val::Float64, index::Int64)\n",
    "    for i = 1:length(p)\n",
    "        if i == index\n",
    "            p[i] = val\n",
    "        else\n",
    "            p[i] = 0.0\n",
    "        end\n",
    "    end\n",
    "end;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function POMDPs.transition(pomdp::Needle,\n",
    "                            state::NeedleState,\n",
    "                            action::Symbol,\n",
    "                            d::NeedleDistribution=create_transition_distribution(pomdp))\n",
    "    tp = pomdp.tprob\n",
    "    \n",
    "    a = action\n",
    "    x = state.x\n",
    "    y = state.y\n",
    "    psi = state.psi\n",
    "    \n",
    "    neighbors = d.neighbors\n",
    "    probability = d.probs\n",
    "    \n",
    "    # let's handle the done case first\n",
    "    if state.done\n",
    "        # can only transition to the same done state\n",
    "        fill!(probability, 0.0)\n",
    "        probability[1] = 1.0\n",
    "        copy!(neighbors[1], state)\n",
    "        # when we sample d, we will only get the state in neighbors[1] - our done state\n",
    "        return d\n",
    "    end\n",
    "    \n",
    "    fill!(probability, 0.0)\n",
    "\n",
    "    if a == :ccw\n",
    "        if psi == 1\n",
    "            neighbors[1].x = x+1; neighbors[1].y = y;   neighbors[1].psi = psi; \n",
    "            neighbors[2].x = x+1; neighbors[2].y = y;   neighbors[2].psi = psi+1;\n",
    "            neighbors[3].x = x+1; neighbors[3].y = y+1; neighbors[3].psi = psi+1;\n",
    "            neighbors[4].x = x+1; neighbors[4].y = y+1; neighbors[4].psi = psi+2;\n",
    "        elseif psi == 2\n",
    "            neighbors[1].x = x+1; neighbors[1].y = y+1; neighbors[1].psi = psi; \n",
    "            neighbors[2].x = x+1; neighbors[2].y = y+1; neighbors[2].psi = psi+1;\n",
    "            neighbors[3].x = x;   neighbors[3].y = y+1; neighbors[3].psi = psi+1;\n",
    "            neighbors[4].x = x;   neighbors[4].y = y+1; neighbors[4].psi = psi+2;\n",
    "        elseif psi == 3\n",
    "            neighbors[1].x = x;   neighbors[1].y = y+1; neighbors[1].psi = psi; \n",
    "            neighbors[2].x = x;   neighbors[2].y = y+1; neighbors[2].psi = psi+1;\n",
    "            neighbors[3].x = x-1; neighbors[3].y = y+1; neighbors[3].psi = psi+1;\n",
    "            neighbors[4].x = x-1; neighbors[4].y = y+1; neighbors[4].psi = psi+2;\n",
    "        elseif psi == 4\n",
    "            neighbors[1].x = x-1; neighbors[1].y = y+1; neighbors[1].psi = psi; \n",
    "            neighbors[2].x = x-1; neighbors[2].y = y+1; neighbors[2].psi = psi+1;\n",
    "            neighbors[3].x = x-1; neighbors[3].y = y;   neighbors[3].psi = psi+1;\n",
    "            neighbors[4].x = x-1; neighbors[4].y = y;   neighbors[4].psi = psi+2;\n",
    "        elseif psi == 5\n",
    "            neighbors[1].x = x-1; neighbors[1].y = y;   neighbors[1].psi = psi; \n",
    "            neighbors[2].x = x-1; neighbors[2].y = y;   neighbors[2].psi = psi+1;\n",
    "            neighbors[3].x = x-1; neighbors[3].y = y-1; neighbors[3].psi = psi+1;\n",
    "            neighbors[4].x = x-1; neighbors[4].y = y-1; neighbors[4].psi = psi+2;\n",
    "        elseif psi == 6\n",
    "            neighbors[1].x = x-1; neighbors[1].y = y-1; neighbors[1].psi = psi; \n",
    "            neighbors[2].x = x-1; neighbors[2].y = y-1; neighbors[2].psi = psi+1;\n",
    "            neighbors[3].x = x;   neighbors[3].y = y-1; neighbors[3].psi = psi+1;\n",
    "            neighbors[4].x = x;   neighbors[4].y = y-1; neighbors[4].psi = psi+2;\n",
    "        elseif psi == 7\n",
    "            neighbors[1].x = x;   neighbors[1].y = y-1; neighbors[1].psi = psi; \n",
    "            neighbors[2].x = x;   neighbors[2].y = y-1; neighbors[2].psi = psi+1;\n",
    "            neighbors[3].x = x+1; neighbors[3].y = y-1; neighbors[3].psi = psi+1;\n",
    "            neighbors[4].x = x+1; neighbors[4].y = y-1; neighbors[4].psi = psi+2;\n",
    "        elseif psi == 8\n",
    "            neighbors[1].x = x+1; neighbors[1].y = y-1; neighbors[1].psi = psi; \n",
    "            neighbors[2].x = x+1; neighbors[2].y = y-1; neighbors[2].psi = psi+1;\n",
    "            neighbors[3].x = x+1; neighbors[3].y = y;   neighbors[3].psi = psi+1;\n",
    "            neighbors[4].x = x+1; neighbors[4].y = y;   neighbors[4].psi = psi+2;\n",
    "        end\n",
    "    elseif a == :cw\n",
    "        if psi == 1\n",
    "            neighbors[1].x = x+1; neighbors[1].y = y;   neighbors[1].psi = psi; \n",
    "            neighbors[2].x = x+1; neighbors[2].y = y;   neighbors[2].psi = psi+7;\n",
    "            neighbors[3].x = x+1; neighbors[3].y = y-1; neighbors[3].psi = psi+7;\n",
    "            neighbors[4].x = x+1; neighbors[4].y = y-1; neighbors[4].psi = psi+6;\n",
    "        elseif psi == 2\n",
    "            neighbors[1].x = x+1; neighbors[1].y = y+1; neighbors[1].psi = psi; \n",
    "            neighbors[2].x = x+1; neighbors[2].y = y+1; neighbors[2].psi = psi+7;\n",
    "            neighbors[3].x = x+1; neighbors[3].y = y;   neighbors[3].psi = psi+7;\n",
    "            neighbors[4].x = x+1; neighbors[4].y = y;   neighbors[4].psi = psi+6;\n",
    "        elseif psi == 3\n",
    "            neighbors[1].x = x;   neighbors[1].y = y+1; neighbors[1].psi = psi; \n",
    "            neighbors[2].x = x;   neighbors[2].y = y+1; neighbors[2].psi = psi+7;\n",
    "            neighbors[3].x = x+1; neighbors[3].y = y+1; neighbors[3].psi = psi+7;\n",
    "            neighbors[4].x = x+1; neighbors[4].y = y+1; neighbors[4].psi = psi+6;\n",
    "        elseif psi == 4\n",
    "            neighbors[1].x = x-1; neighbors[1].y = y+1; neighbors[1].psi = psi; \n",
    "            neighbors[2].x = x-1; neighbors[2].y = y+1; neighbors[2].psi = psi+7;\n",
    "            neighbors[3].x = x;   neighbors[3].y = y+1; neighbors[3].psi = psi+7;\n",
    "            neighbors[4].x = x;   neighbors[4].y = y+1; neighbors[4].psi = psi+6;\n",
    "        elseif psi == 5\n",
    "            neighbors[1].x = x-1; neighbors[1].y = y;   neighbors[1].psi = psi; \n",
    "            neighbors[2].x = x-1; neighbors[2].y = y;   neighbors[2].psi = psi+7;\n",
    "            neighbors[3].x = x-1; neighbors[3].y = y+1; neighbors[3].psi = psi+7;\n",
    "            neighbors[4].x = x-1; neighbors[4].y = y+1; neighbors[4].psi = psi+6;\n",
    "        elseif psi == 6\n",
    "            neighbors[1].x = x-1; neighbors[1].y = y-1; neighbors[1].psi = psi; \n",
    "            neighbors[2].x = x-1; neighbors[2].y = y-1; neighbors[2].psi = psi+7;\n",
    "            neighbors[3].x = x-1; neighbors[3].y = y;   neighbors[3].psi = psi+7;\n",
    "            neighbors[4].x = x-1; neighbors[4].y = y;   neighbors[4].psi = psi+6;\n",
    "        elseif psi == 7\n",
    "            neighbors[1].x = x;   neighbors[1].y = y-1; neighbors[1].psi = psi; \n",
    "            neighbors[2].x = x;   neighbors[2].y = y-1; neighbors[2].psi = psi+7;\n",
    "            neighbors[3].x = x-1; neighbors[3].y = y-1; neighbors[3].psi = psi+7;\n",
    "            neighbors[4].x = x-1; neighbors[4].y = y-1; neighbors[4].psi = psi+6;\n",
    "        elseif psi == 8\n",
    "            neighbors[1].x = x+1; neighbors[1].y = y-1; neighbors[1].psi = psi; \n",
    "            neighbors[2].x = x+1; neighbors[2].y = y-1; neighbors[2].psi = psi+7;\n",
    "            neighbors[3].x = x;   neighbors[3].y = y-1; neighbors[3].psi = psi+7;\n",
    "            neighbors[4].x = x;   neighbors[4].y = y-1; neighbors[4].psi = psi+6;\n",
    "        end\n",
    "    end\n",
    "    # make sure psi is between 1 and 8\n",
    "    for i = 1:4\n",
    "        neighbors[i].psi = mod(neighbors[i].psi,8)\n",
    "        if neighbors[i].psi == 0\n",
    "            neighbors[i].psi = 8;\n",
    "        end\n",
    "    end\n",
    "    neighbors[5].x = x; neighbors[5].y = y; neighbors[5].psi = psi;\n",
    "    \n",
    "    # initialize bumped and done states \n",
    "    for i = 1:5 neighbors[i].bumped = false end\n",
    "    for i = 1:5 neighbors[i].done = false end\n",
    "    reward_states = pomdp.reward_states\n",
    "    \n",
    "    # detection of done states\n",
    "    n = length(reward_states)\n",
    "    for i = 1:n\n",
    "        # terminate at target/obstacle\n",
    "        if posequal(state, reward_states[i])\n",
    "            fill_probability!(probability, 1.0, 5)\n",
    "            neighbors[5].done = true\n",
    "            return d\n",
    "        end\n",
    "        # terminate at boundary\n",
    "        if atbounds(pomdp, state)\n",
    "            fill_probability!(probability, 1.0, 5)\n",
    "            neighbors[5].done = true\n",
    "            neighbors[5].bumped = true\n",
    "            return d\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    if !inbounds(pomdp, neighbors[1]) || !inbounds(pomdp, neighbors[2]) ||\n",
    "        !inbounds(pomdp, neighbors[3]) || !inbounds(pomdp, neighbors[4]) # at least one of the neighbors is outside bounds\n",
    "        fill_probability!(probability, 1.0, 5) # stuck in current state when terminated\n",
    "        neighbors[5].bumped = true     \n",
    "    else # none of the neighbors is outside bounds\n",
    "        probability[1:4] = tp\n",
    "    end\n",
    "    \n",
    "    return d\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation Model (O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function POMDPs.observation(pomdp::Needle,\n",
    "                           action::Symbol,\n",
    "                           state::NeedleState,\n",
    "                           d::ObsDistribution=create_observation_distribution(pomdp))\n",
    "    a = action\n",
    "    x = state.x\n",
    "    y = state.y\n",
    "    psi = state.psi\n",
    "    d.curr_obs = NeedleState(x, y, psi);\n",
    "    return d\n",
    "end\n",
    "\n",
    "POMDPs.observation(pomdp::Needle,\n",
    "                   state::NeedleState,\n",
    "                   action::Symbol,\n",
    "                   sp::NeedleState,\n",
    "                    d::ObsDistribution = create_observation_distribution(pomdp)) = observation(pomdp, action, sp, d);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward Model (R)\n",
    "The reward model $R(s,a,s')$ is a function that returns the reward of being in state $s$, taking an action $a$ from that state, and ending up in state $s'$. In our problem, we are rewarded for reaching a terimanl reward state (this could be positive or negative), and we are penalized for bumping into a wall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function POMDPs.reward(pomdp::Needle, state::NeedleState, action::Symbol) #deleted action\n",
    "    if state.done\n",
    "        return 0.0\n",
    "    end\n",
    "    r = 0.0\n",
    "    reward_states = pomdp.reward_states\n",
    "    reward_values = pomdp.reward_values\n",
    "    n = length(reward_states)\n",
    "    for i = 1:n\n",
    "        if posequal(state, reward_states[i]) # reward, obstacle and wall states\n",
    "            r += reward_values[i]\n",
    "        end\n",
    "    end\n",
    "    r += -1; # penalty for every step taken\n",
    "    return r\n",
    "end;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "POMDPs.n_states(pomdp::Needle) = 4*pomdp.size_x*pomdp.size_y*pomdp.size_psi\n",
    "POMDPs.n_actions(pomdp::Needle) = 2;\n",
    "POMDPs.n_observations(pomdp::Needle) = 4*pomdp.size_x*pomdp.size_y*pomdp.size_psi;\n",
    "POMDPs.discount(pomdp::Needle) = pomdp.discount_factor;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function POMDPs.state_index(pomdp::Needle, state::NeedleState)\n",
    "    sb = Int(state.bumped + 1)\n",
    "    sd = Int(state.done + 1)\n",
    "    return sub2ind((pomdp.size_x, pomdp.size_y, pomdp.size_psi, 2, 2), state.x, state.y, state.psi, sb, sd)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function POMDPs.isterminal(pomdp::Needle, s::NeedleState)\n",
    "    s.done ? (return true) : (return false)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "POMDPs.create_state(pomdp::Needle) = NeedleState(1,1,1)\n",
    "POMDPs.create_action(pomdp::Needle) = :cw;\n",
    "POMDPs.create_observation(pomd::Needle) = NeedleState(1,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SARSOP Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating a pomdpx file: model.pomdpx\n",
      "\n",
      "Loading the model ...\n",
      "  input file   : model.pomdpx\n",
      "  loading time : 3.03s \n",
      "\n",
      "SARSOP initializing ...\n",
      "  initialization time : 0.12s\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      " Time   |#Trial |#Backup |LBound    |UBound    |Precision  |#Alphas |#Beliefs  \n",
      "-------------------------------------------------------------------------------\n",
      " 0.12    0       0        -1.52917   7.48277    9.01194     2        1        \n",
      " 1.3     5       55       3.79431    4.49447    0.700162    28       29       \n",
      " 2.26    6       100      4.02999    4.49447    0.464481    64       47       \n",
      " 3.44    9       155      4.2044     4.49447    0.290066    108      65       \n",
      " 4.4     11      200      4.24737    4.49447    0.247099    139      82       \n",
      " 5.45    14      250      4.30918    4.49447    0.185289    182      99       \n",
      " 6.55    15      300      4.35344    4.49447    0.141026    218      113      \n",
      " 7.67    17      350      4.38503    4.49447    0.10944     252      120      \n",
      " 8.8     19      400      4.40619    4.49447    0.0882837   292      132      \n",
      " 9.94    21      450      4.41637    4.49447    0.0780951   327      144      \n",
      " 11.12   24      500      4.44291    4.49447    0.0515638   370      158      \n",
      " 12.43   28      553      4.45668    4.49447    0.037788    412      167      \n",
      " 13.63   32      600      4.46588    4.49447    0.0285942   437      182      \n",
      " 14.91   36      650      4.47456    4.49447    0.0199094   475      193      \n",
      " 16.25   38      703      4.48043    4.49447    0.0140388   513      196      \n",
      " 17.52   40      750      4.48447    4.49447    0.0100035   552      201      \n",
      " 18.88   43      800      4.48751    4.49447    0.00695555  588      210      \n",
      " 20.03   47      850      4.48917    4.49447    0.00530414  638      212      \n",
      " 21.48   48      900      4.49011    4.49447    0.00436422  671      215      \n",
      " 22.69   53      950      4.49122    4.49447    0.00325265  721      218      \n",
      " 24.24   57      1000     4.49165    4.49447    0.002815    744      226      \n",
      " 25.46   60      1055     4.49218    4.49447    0.00229191  799      230      \n",
      " 26.51   62      1100     4.49249    4.49447    0.00198359  826      231      \n",
      " 28.23   66      1150     4.49281    4.49447    0.00166326  852      232      \n",
      " 29.37   68      1200     4.49318    4.49447    0.00128852  902      234      \n",
      " 30.57   70      1250     4.49339    4.49447    0.00108046  938      236      \n",
      " 31.55   72      1285     4.49348    4.49447    0.000987004 973      236      \n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "SARSOP finishing ...\n",
      "  target precision reached\n",
      "  target precision  : 0.001000\n",
      "  precision reached : 0.000987 \n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      " Time   |#Trial |#Backup |LBound    |UBound    |Precision  |#Alphas |#Beliefs  \n",
      "-------------------------------------------------------------------------------\n",
      " 31.61   72      1285     4.49348    4.49447    0.000987004 967      236      \n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "Writing out policy ...\n",
      "  output file : out.policy\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SARSOP.POMDPPolicy(\"out.policy\",POMDPXFiles.POMDPAlphas([-1.0 -1.0 … -1.0 -1.0; -1.0 -1.0 … -1.0 -1.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0],[0,0,0,0,0,0,0,0,0,0  …  0,0,0,0,0,0,0,0,0,1]),Needle(10,10,8,NeedleState[NeedleState(8,4,1,false,false),NeedleState(8,4,2,false,false),NeedleState(8,4,3,false,false),NeedleState(8,4,4,false,false),NeedleState(8,4,5,false,false),NeedleState(8,4,6,false,false),NeedleState(8,4,7,false,false),NeedleState(8,4,8,false,false),NeedleState(4,6,1,false,false),NeedleState(4,6,2,false,false)  …  NeedleState(8,10,4,false,false),NeedleState(9,10,4,false,false),NeedleState(2,10,5,false,false),NeedleState(3,10,5,false,false),NeedleState(4,10,5,false,false),NeedleState(5,10,5,false,false),NeedleState(6,10,5,false,false),NeedleState(7,10,5,false,false),NeedleState(8,10,5,false,false),NeedleState(9,10,5,false,false)],[100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,-20.0,-20.0  …  -5.0,-5.0,-5.0,-5.0,-5.0,-5.0,-5.0,-5.0,-5.0,-5.0],[0.05,0.9,0.05,0.0],0.9),Any[:cw,:ccw])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using SARSOP # load the module\n",
    "# initialize our tiger POMDP\n",
    "pomdp = Needle()\n",
    "\n",
    "# initialize the solver\n",
    "solver = SARSOPSolver()\n",
    "# run the solve function\n",
    "policy = solve(solver, pomdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using JLD\n",
    "filename = \"SARSOP policy\"\n",
    "JLD.save(string(filename,\".jld\"),\"policy\",policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String,Any} with 1 entry:\n",
       "  \"policy\" => SARSOP.POMDPPolicy(\"out.policy\",POMDPXFiles.POMDPAlphas([-1.0 -1.…"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"SARSOP policy\"\n",
    "d = JLD.load(string(filename,\".jld\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SARSOP.POMDPPolicy(\"out.policy\",POMDPXFiles.POMDPAlphas([-1.0 -1.0 … -1.0 -1.0; -1.0 -1.0 … -1.0 -1.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0],[0,0,0,0,0,0,0,0,0,0  …  0,0,0,0,0,0,0,0,0,1]),Needle(10,10,8,NeedleState[NeedleState(8,4,1,false,false),NeedleState(8,4,2,false,false),NeedleState(8,4,3,false,false),NeedleState(8,4,4,false,false),NeedleState(8,4,5,false,false),NeedleState(8,4,6,false,false),NeedleState(8,4,7,false,false),NeedleState(8,4,8,false,false),NeedleState(4,6,1,false,false),NeedleState(4,6,2,false,false)  …  NeedleState(8,10,4,false,false),NeedleState(9,10,4,false,false),NeedleState(2,10,5,false,false),NeedleState(3,10,5,false,false),NeedleState(4,10,5,false,false),NeedleState(5,10,5,false,false),NeedleState(6,10,5,false,false),NeedleState(7,10,5,false,false),NeedleState(8,10,5,false,false),NeedleState(9,10,5,false,false)],[100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,-20.0,-20.0  …  -5.0,-5.0,-5.0,-5.0,-5.0,-5.0,-5.0,-5.0,-5.0,-5.0],[0.05,0.9,0.05,0.0],0.9),Any[:cw,:ccw])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy2 = d[\"policy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "PyPlot.Figure(PyObject <matplotlib.figure.Figure object at 0x7f9a6b29e690>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total discounted reward: 0.0\n",
      "Target missed\n"
     ]
    }
   ],
   "source": [
    "using POMDPToolbox\n",
    "\n",
    "init_state = initial_state_distribution(pomdp)\n",
    "hist_SARSOP = HistoryRecorder(max_steps=100)\n",
    "r = simulate(hist_SARSOP, pomdp, policy, updater(policy), init_state)\n",
    "\n",
    "println(\"Total discounted reward: $r\")\n",
    "\n",
    "if hist_SARSOP.state_hist[end].x == pomdp.reward_states[1].x && hist_SARSOP.state_hist[end].y == pomdp.reward_states[1].y\n",
    "    println(\"Target reached\")\n",
    "else\n",
    "    println(\"Target missed\")\n",
    "end\n",
    "\n",
    "# define tissue environment\n",
    "plot([1 10 10 1 1]',[1 1 10 10 1]',linewidth=10,color=\"r\") # tissue bounds\n",
    "plot(pomdp.reward_states[1].x,pomdp.reward_states[1].y,marker=\"o\",markersize=40,color=\"g\",markeredgecolor=\"none\")\n",
    "plot(pomdp.reward_states[9].x,pomdp.reward_states[9].y,marker=\"o\",markersize=40,color=\"r\",markeredgecolor=\"none\")\n",
    "hold(true)\n",
    "\n",
    "for state in hist_SARSOP.state_hist\n",
    "    plot(state.x,state.y,color=\"b\",marker=\"o\")\n",
    "    quiver(state.x,state.y,0.5*cos((state.psi-1)*pi/4),0.5*sin((state.psi-1)*pi/4))\n",
    "end\n",
    "\n",
    "title(\"Needle tip trajectory (value iteration)\")\n",
    "axis(\"equal\")\n",
    "axis([0, 11, 0, 11])\n",
    "xlabel(\"x\")\n",
    "ylabel(\"y\")\n",
    "grid(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using DiscreteValueIteration\n",
    "\n",
    "# initialize the problem\n",
    "mdp = Needle()\n",
    "\n",
    "# initialize the solver\n",
    "# max_iterations: maximum number of iterations value iteration runs for (default is 100)\n",
    "# belres: the value of Bellman residual used in the solver (defualt is 1e-3)\n",
    "solver = ValueIterationSolver(max_iterations=100, belres=1e-3)\n",
    "\n",
    "# initialize the policy by passing in your problem\n",
    "policy_vi = ValueIterationPolicy(mdp)\n",
    "\n",
    "# solve for an optimal policy\n",
    "# if verbose=false, the text output will be supressed (false by default)\n",
    "solve(solver, mdp, policy_vi, verbose=true);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte-Carlo Tree Search Solver\n",
    "Monte-Carlo Tree Search (MCTS) is another MDP solver. It is an online method that looks for the best action from only the current state by building a search tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using MCTS\n",
    "\n",
    "# initialize the problem\n",
    "mdp = Needle()\n",
    "\n",
    "# initialize the solver\n",
    "# the hyper parameters in MCTS can be tricky to set properly\n",
    "# n_iterations: the number of iterations that each search runs for\n",
    "# depth: the depth of the tree (how far away from the current state the algorithm explores)\n",
    "# exploration constant: this is how much weight to put into exploratory actions. \n",
    "# A good rule of thumb is to set the exploration constant to what you expect the upper bound on your average expected reward to be.\n",
    "solver = MCTSSolver(n_iterations=100, depth=10, exploration_constant=1.0)\n",
    "\n",
    "# initialize the policy by passing in your problem and the solver\n",
    "policy_MCTS = MCTSPolicy(solver, mdp);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = NeedleState(4,10,7)\n",
    "hist_vi = HistoryRecorder()\n",
    "\n",
    "r = simulate(hist_vi, mdp, policy_vi, s)\n",
    "\n",
    "println(\"Total discounted reward: $r\")\n",
    "\n",
    "if hist_MCTS.state_hist[end].x == mdp.reward_states[1].x && hist_MCTS.state_hist[end].y == mdp.reward_states[1].y\n",
    "    println(\"Target reached\")\n",
    "else\n",
    "    println(\"Target missed\")\n",
    "end\n",
    "\n",
    "# define tissue environment\n",
    "plot([1 10 10 1 1]',[1 1 10 10 1]',linewidth=10,color=\"r\") # tissue bounds\n",
    "plot(mdp.reward_states[1].x,mdp.reward_states[1].y,marker=\"o\",markersize=40,color=\"g\",markeredgecolor=\"none\")\n",
    "plot(mdp.reward_states[9].x,mdp.reward_states[9].y,marker=\"o\",markersize=40,color=\"r\",markeredgecolor=\"none\")\n",
    "hold(true)\n",
    "\n",
    "for state in hist_vi.state_hist\n",
    "    plot(state.x,state.y,color=\"b\",marker=\"o\")\n",
    "    quiver(state.x,state.y,0.5*cos((state.psi-1)*pi/4),0.5*sin((state.psi-1)*pi/4))\n",
    "end\n",
    "\n",
    "title(\"Needle tip trajectory (value iteration)\")\n",
    "axis(\"equal\")\n",
    "axis([0, 11, 0, 11])\n",
    "xlabel(\"x\")\n",
    "ylabel(\"y\")\n",
    "grid(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = NeedleState(4,10,7)\n",
    "\n",
    "hist_MCTS = HistoryRecorder()\n",
    "r = simulate(hist_MCTS, mdp, policy_MCTS, s)\n",
    "\n",
    "println(\"Total discounted reward: $r\")\n",
    "\n",
    "if hist_MCTS.state_hist[end].x == mdp.reward_states[1].x && hist_MCTS.state_hist[end].y == mdp.reward_states[1].y\n",
    "    println(\"Target reached\")\n",
    "else\n",
    "    println(\"Target missed\")\n",
    "end\n",
    "\n",
    "# define tissue environment\n",
    "plot([1 10 10 1 1]',[1 1 10 10 1]',linewidth=10,color=\"r\") # tissue bounds\n",
    "plot(mdp.reward_states[1].x,mdp.reward_states[1].y,marker=\"o\",markersize=40,color=\"g\",markeredgecolor=\"none\")\n",
    "plot(mdp.reward_states[9].x,mdp.reward_states[9].y,marker=\"o\",markersize=40,color=\"r\",markeredgecolor=\"none\")\n",
    "hold(true)\n",
    "\n",
    "for state in hist_MCTS.state_hist\n",
    "    plot(state.x,state.y,color=\"b\",marker=\"o\")\n",
    "    quiver(state.x,state.y,0.5*cos((state.psi-1)*pi/4),0.5*sin((state.psi-1)*pi/4))\n",
    "end\n",
    "\n",
    "title(\"Needle tip trajectory (MCTS)\")\n",
    "axis(\"equal\")\n",
    "axis([0, 11, 0, 11])\n",
    "xlabel(\"x\")\n",
    "ylabel(\"y\")\n",
    "grid(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# N = 100000\n",
    "# r_all = ones(1,N)\n",
    "# for i = 1:N\n",
    "#     r_all[i] = simulate(hist_vi, mdp, policy_vi, s)\n",
    "# end\n",
    "# println(value(policy_vi, s))\n",
    "# mean(r_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
