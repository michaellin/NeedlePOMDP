{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using POMDPs\n",
    "using Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define the state and the observed state\n",
    "type GridWorldState \n",
    "    x::Int64 # x tip position\n",
    "    y::Int64 # y tip position\n",
    "    θ::Int64 # θ tip angle\n",
    "    done::Bool # are we in a terminal state; if so later will set reward to 0\n",
    "end\n",
    "\n",
    "type ObservedState\n",
    "    xobs::Int64 # x observed tip position\n",
    "    yobs::Int64 # y observed tip position\n",
    "    θobs::Int64 # θ observed tip angle\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define the POMDP container\n",
    "type GridWorld <: POMDP{GridWorldState, Symbol, ObservedState}  #action is \"symbol\".. left or right\n",
    "    size_x::Int64 #grid size\n",
    "    size_y::Int64 #grid size\n",
    "    size_θ::Int64 #thetas possible.  8 buckets of angles\n",
    "    reward_states::Vector{GridWorldState} # the states in which agent recieves reward\n",
    "    reward_values::Vector{Float64} # reward values for those states\n",
    "    penalty::Float64 # penalty for taking more steps to reach\n",
    "    tprob::Float64 # probability of transitioning to the desired state\n",
    "    discount_factor::Float64 # discount factor\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element Array{GridWorldState,1}:\n",
       " GridWorldState(4,3,1,false)\n",
       " GridWorldState(4,3,2,false)\n",
       " GridWorldState(4,3,3,false)\n",
       " GridWorldState(4,3,4,false)\n",
       " GridWorldState(4,3,5,false)\n",
       " GridWorldState(4,3,6,false)\n",
       " GridWorldState(4,3,7,false)\n",
       " GridWorldState(4,3,8,false)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Constructor of gridworld with some default values\n",
    "# initial state constructor\n",
    "#Set target location at rs.\n",
    "GridWorldState(x::Int64, y::Int64, θ::Int64) = GridWorldState(x,y,θ,false)\n",
    "function GridWorld(;sx::Int64=10, # size_x\n",
    "                    sy::Int64=10, # size_y\n",
    "                    sθ::Int64=8, # size_theta\n",
    "                    rs::Vector{GridWorldState}=[GridWorldState(4,3,1),GridWorldState(4,3,2),GridWorldState(4,3,3),GridWorldState(4,3,4),GridWorldState(4,3,5),GridWorldState(4,3,6),GridWorldState(4,3,7),GridWorldState(4,3,8)], # reward states.  x=4,y=3,theta any\n",
    "                    rv::Vector{Float64}=rv = [100.,100,100,100,100,100,100,100], # reward value\n",
    "                    pen::Float64=-1.0, # penalty for each move made\n",
    "                    tp::Float64=0.7, ########## tprob depends on where you go to by transition distribution function which will be encoded later?\n",
    "                    df::Float64=0.9) #discount factor\n",
    "    return GridWorld(sx, sy, sθ, rs, rv, pen, tp, df)\n",
    "end\n",
    "# we can now create a GridWorld pomdp instance like this:\n",
    "pomdp = GridWorld()\n",
    "pomdp.reward_states # pomdp contains all the default values from the constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#State Space\n",
    "type StateSpace <: AbstractSpace\n",
    "    states::Vector{GridWorldState}\n",
    "end\n",
    "\n",
    "#Alter the function states so that it \"knows\" the GridWorld datatype we defined\n",
    "function POMDPs.states(pomdp::GridWorld)\n",
    "    s = GridWorldState[] # initialize an array of GridWorldStates\n",
    "    # loop over all our states, binary variable: done (d)\n",
    "    for d = 0:1, y = 1:pomdp.size_y, x = 1:pomdp.size_x, θ = 1:pomdp.size_θ\n",
    "        push!(s, GridWorldState(x,y,θ,d))\n",
    "    end\n",
    "    return StateSpace(s)\n",
    "end\n",
    "\n",
    "# How state space calls this function:\n",
    "state_space = states(pomdp);\n",
    "state_space.states[1] # remeber that our state space instance has an array called states in it\n",
    "\n",
    "#Define iterator\n",
    "function POMDPs.iterator(space::StateSpace)\n",
    "    return space.states \n",
    "end\n",
    "\n",
    "# Uniform sampling if have matrix of state space:\n",
    "function POMDPs.rand(rng::AbstractRNG, space::StateSpace, s::GridWorldState)\n",
    "    sp = space.states[rand(rng, 1:end)]\n",
    "    copy!(s, sp)\n",
    "    s\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Action Space:\n",
    "type ActionSpace <: AbstractSpace\n",
    "    actions::Vector{Symbol}\n",
    "end\n",
    "\n",
    "# Function to return action space:\n",
    "function POMDPs.actions(pomdp::GridWorld)\n",
    "    acts = [:left, :right]\n",
    "    return ActionSpace(acts)\n",
    "end;\n",
    "POMDPs.actions(pomdp::GridWorld, s::GridWorldState, as::ActionSpace=actions(pomdp)) = as;\n",
    "\n",
    "# Iterator function for action space:\n",
    "function POMDPs.iterator(space::ActionSpace)\n",
    "    return space.actions \n",
    "end;\n",
    "\n",
    "#Function to sample from action space:\n",
    "function POMDPs.rand(rng::AbstractRNG, space::ActionSpace, a::Symbol)\n",
    "    return space.actions[rand(rng, 1:end)]\n",
    "end;\n",
    "\n",
    "# Initialize action space and action space:\n",
    "POMDPs.create_state(pomdp::GridWorld) = GridWorldState(1,1,0) # the 0 is an initial theta, x=1,y=1\n",
    "POMDPs.create_action(pomdp::GridWorld) = :left;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Observation Space:\n",
    "type ObservationSpace <: AbstractSpace\n",
    "    obs::Vector{GridWorldState} \n",
    "end\n",
    "\n",
    "# function returning observation space\n",
    "function POMDPs.observations(pomdp::GridWorld)\n",
    "    obs= GridWorldState[]\n",
    "    # loop over all states\n",
    "    for y = 1:pomdp.size_y, x = 1:pomdp.size_x, θ = 1:pomdp.size_θ\n",
    "        push!(s, GridWorldState(x,y,θ))\n",
    "    end\n",
    "    return ObservationSpace(obs);\n",
    "end;\n",
    "POMDPs.observations(::GridWorld, s::GridWorldState, obs::ObservationSpace) = obs;\n",
    "\n",
    "# function returning an iterator over that space\n",
    "function POMDPs.iterator(space::ObservationSpace)\n",
    "    return space.observations\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transition Distribution:\n",
    "type TransitionDistribution <: AbstractDistribution\n",
    "    neighbors::Array{GridWorldState} # the states s' in the distribution\n",
    "    probs::Array{Float64} # the probability corresponding to each state s'\n",
    "    cat::Categorical # this comes from Distributions.jl and is used for sampling\n",
    "end\n",
    "\n",
    "function POMDPs.create_transition_distribution(pomdp::GridWorld)\n",
    "    # can have at most 9 neighbors in grid world\n",
    "    neighbors =  [GridWorldState(i,i) for i = 1:9] #initializing. these will get overwritten by action and tprob=.7\n",
    "    probabilities = zeros(9) + 1.0/9.0\n",
    "    cat = Categorical(9)\n",
    "    return TransitionDistribution(neighbors, probabilities, cat)\n",
    "end;\n",
    "\n",
    "#Iterator for distributions for d:\n",
    "function POMDPs.iterator(d::TransitionDistribution)\n",
    "    return d.neighbors\n",
    "end;\n",
    "\n",
    "#Prob. density function:\n",
    "function POMDPs.pdf(d::TransitionDistribution, s::GridWorldState)\n",
    "    for (i, sp) in enumerate(d.neighbors)\n",
    "        if s == sp\n",
    "            return d.probs[i]\n",
    "        end\n",
    "    end   \n",
    "    return 0.0\n",
    "end;\n",
    "\n",
    "#Iterator for PDF:\n",
    "function POMDPs.rand(rng::AbstractRNG, d::TransitionDistribution, s::GridWorldState)\n",
    "    d.cat = Categorical(d.probs) # init the categorical distribution\n",
    "    ns = d.neighbors[rand(d.cat)] # sample a neighbor state according to the distribution c\n",
    "    copy!(s, ns)\n",
    "    return s # return the pointer to s\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Observation distribution:\n",
    "type ObservationDistribution <: AbstractDistribution\n",
    "    neighbors::Array{GridWorldState} # the states s' in the distribution\n",
    "    probs::Array{Float64} # the probability corresponding to each state s'\n",
    "    cat::Categorical # this comes from Distributions.jl and is used for sampling\n",
    "end\n",
    "\n",
    "function POMDPs.create_observation_distribution(pomdp::GridWorld)\n",
    "    # can have at most 9 neighbors in grid world\n",
    "    neighbors =  [GridWorldState(i,i) for i = 1:9] #initializing. these will get overwritten by action and tprob=.7\n",
    "    probabilities = zeros(9) + 1.0/9.0\n",
    "    cat = Categorical(9)\n",
    "    return ObservationDistribution(neighbors, probabilities, cat)\n",
    "end;\n",
    "\n",
    "#Iterator for distributions for d:\n",
    "function POMDPs.iterator(d::ObservationDistribution)\n",
    "    return d.neighbors\n",
    "end;\n",
    "\n",
    "#Prob. density function:\n",
    "function POMDPs.pdf(d::ObservationDistribution, s::GridWorldState)\n",
    "    for (i, sp) in enumerate(d.neighbors)\n",
    "        if s == sp\n",
    "            return d.probs[i]\n",
    "        end\n",
    "    end   \n",
    "    return 0.0\n",
    "end;\n",
    "\n",
    "#Iterator for PDF:\n",
    "function POMDPs.rand(rng::AbstractRNG, d::ObservationDistribution, s::GridWorldState)\n",
    "    d.cat = Categorical(d.probs) # init the categorical distribution\n",
    "    ns = d.neighbors[rand(d.cat)] # sample a neighbor state according to the distribution c\n",
    "    copy!(s, ns)\n",
    "    return s # return the pointer to s\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transition Model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reward Model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Observation Model:\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
